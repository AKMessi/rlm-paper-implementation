# ğŸ”„ RLM - Recursive Language Model

> True implementation of **"Recursive Language Models"** from MIT  
> Process 10M+ token documents through symbolic recursion

[![Tests](https://img.shields.io/badge/tests-16%2F16%20passing-brightgreen)]() [![Python](https://img.shields.io/badge/python-3.10%2B-blue)]() [![License](https://img.shields.io/badge/license-MIT-green)]()

---

## ğŸ¤¯ What is this?

This is a **true implementation** of [Algorithm 1](RLM_IMPLEMENTATION.md) from the paper *"Recursive Language Models"* by Zhang et al. (MIT CSAIL, 2026).

**The Problem:** LLMs have limited context windows (~128K tokens). Traditional RAG uses embeddings that miss nuanced connections.

**The Solution:** RLM treats the prompt as a **REPL environment variable**. The LLM writes Python code to:
1. ğŸ” Examine the context programmatically  
2. ğŸ”„ Call itself recursively via `llm_query()` on chunks
3. ğŸ§  Build up answers through symbolic manipulation
4. âœ… Set `Final` variable when done

**Result:** Handles 10M+ tokens (2 orders of magnitude beyond context limits).

---

## âœ¨ Features

- ğŸ“„ **10M+ Token Support** - Process arbitrarily long documents
- ğŸ¯ **True RLM Algorithm** - Exact implementation of Algorithm 1 from paper
- ğŸ”‘ **BYOK** - Users bring their own API keys (zero cost to deployer)
- ğŸ¤– **15+ LLM Providers** - OpenAI, Anthropic, Google, Groq, Together, Mistral, Cohere, DeepSeek, Perplexity, Azure, Ollama
- ğŸ“‘ **Multi-Format** - PDF, DOCX, TXT, Markdown, JSON, Code files
- ğŸŒ **Web UI** - Modern interface for upload & chat
- âš¡ **FastAPI Backend** - REST API for integration

---

## ğŸ¬ Demo

**Live Demo:** https://rlm-ucnx.onrender.com/web

![Demo](https://img.shields.io/badge/ğŸš€-Try%20it%20now-blue)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Prompt   â”‚â”€â”€â”€â”€â–¶â”‚  REPL Environment â”‚â”€â”€â”€â”€â–¶â”‚  LLM Generates â”‚
â”‚   (10M tokens)  â”‚     â”‚  context = P      â”‚     â”‚  Python Code   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Return Final   â”‚â—€â”€â”€â”€â”€â”‚ Check Final var â”‚â—€â”€â”€â”€â”€â”‚  Execute Code   â”‚
â”‚     Answer      â”‚     â”‚  in REPL state  â”‚     â”‚  in REPL        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ llm_query() for â”‚
                        â”‚ recursive calls â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

```bash
# Clone & setup
git clone https://github.com/AKMessi/rlm-paper-implementation.git
cd rlm-paper-implementation/rlm_app

# Create venv
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install
pip install -r requirements.txt

# Run
python -m backend.main
```

Open http://localhost:8000/web

---

## ğŸ“– How It Works

### Traditional RAG
```
Document â†’ Chunks â†’ Embeddings â†’ Vector DB â†’ Similarity Search â†’ LLM
```
âŒ Static, loses nuance, embedding bottleneck

### RLM (This Implementation)
```
Document â†’ REPL Variable â†’ LLM Writes Code â†’ Code Examines Doc
                â†“
        llm_query() chunks â†’ Aggregate â†’ Set Final Variable
```
âœ… Dynamic, programmable, unbounded context

---

## ğŸ“¡ API Usage

### 1. Set API Keys (BYOK)
```bash
POST /api/keys
{
  "session_id": "your-session-id",
  "openai_api_key": "sk-...",
  "root_model": "gpt-4o",
  "sub_model": "gpt-4o-mini"
}
```

### 2. Upload Document
```bash
POST /upload
Content-Type: multipart/form-data

file: @your-document.pdf
session_id: your-session-id
```

### 3. Query with RLM
```bash
POST /query
{
  "session_id": "your-session-id",
  "query": "What are the key findings?",
  "max_iterations": 10
}
```

**Response:**
```json
{
  "success": true,
  "answer": "The key findings are...",
  "iterations": 3,
  "sub_lm_calls": 5,
  "processing_time_seconds": 12.5
}
```

---

## ğŸ§ª Testing

```bash
# Run all tests
python -m pytest tests/ -v

# 16 tests covering:
# - REPL state management
# - Code execution
# - Algorithm 1 loop
# - Final variable termination
```

---

## ğŸ›ï¸ Paper Reference

**"Recursive Language Models"**  
Alex L. Zhang, Tim Kraska, Omar Khattab  
MIT CSAIL, January 2026

**Key Innovation:** Algorithm 1 - RLM scaffold with:
- âœ“ Prompt as REPL variable (not context window)
- âœ“ LLM generates code (not chat)
- âœ“ Symbolic recursion via `llm_query()`
- âœ“ Termination via `Final` variable
- âœ“ Constant-size history

[Read full implementation details â†’](RLM_IMPLEMENTATION.md)

---

## ğŸ¤ Credits

- **Paper Authors:** [@a1zhang](https://twitter.com/a1zhang) & [@lateinteraction](https://twitter.com/lateinteraction) (Omar Khattab)
- **Implementation:** [@AKMessi](https://github.com/AKMessi)
- **Institution:** MIT CSAIL

---

## ğŸ“œ License

MIT License - Feel free to use, modify, deploy!

---

## ğŸŒŸ Star History

If you find this useful, please â­ star the repo!

[![Star History Chart](https://img.shields.io/github/stars/AKMessi/rlm-paper-implementation?style=social)]()

---

<p align="center">
  <b>ğŸ”„ Process the impossible. Recursively.</b>
</p>
